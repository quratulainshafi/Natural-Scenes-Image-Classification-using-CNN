{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_Assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlZpjzh-eWQZ"
      },
      "source": [
        "from PIL import Image\r\n",
        "from PIL import Image as pil_image\r\n",
        "from time import time\r\n",
        "from PIL import ImageDraw\r\n",
        "from glob import glob\r\n",
        "from tqdm import tqdm\r\n",
        "from skimage.io import imread\r\n",
        "from IPython.display import SVG\r\n",
        "from scipy import misc,ndimage\r\n",
        "from scipy.ndimage.interpolation import zoom\r\n",
        "import pandas as pd\r\n",
        "import os,shutil,math,scipy,cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from sklearn.metrics import confusion_matrix,roc_curve,auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrNVsuOKgOKd"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJJ1INHJeZg9"
      },
      "source": [
        "!mkdir ~/.kaggle #created at root folder in colab\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN_13Bv6ec2g"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuq329J0ee5d"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q6-6gq7ehJl"
      },
      "source": [
        "!kaggle datasets download -d puneet6060/intel-image-classification\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIMRXLJoejJc"
      },
      "source": [
        "!unzip -q intel-image-classification.zip # -q for quiet\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nGmKOscelqW"
      },
      "source": [
        "train_dir = 'seg_train/seg_train/'\r\n",
        "test_dir = 'seg_test/seg_test/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS3S4feJgFUY"
      },
      "source": [
        "from keras import backend as K\r\n",
        "from keras import layers\r\n",
        "from keras.preprocessing.image import save_img\r\n",
        "from keras.utils.vis_utils import model_to_dot\r\n",
        "from keras.applications.vgg19 import VGG19,preprocess_input\r\n",
        "from keras.applications.xception import Xception\r\n",
        "from keras.applications.nasnet import NASNetMobile\r\n",
        "from keras.models import Sequential,Input,Model\r\n",
        "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\r\n",
        "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.optimizers import Adam,SGD\r\n",
        "from keras.utils.vis_utils import plot_model\r\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXV-x3PqepvT"
      },
      "source": [
        "generator = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    shear_range=0.2,  \r\n",
        "    zoom_range=0.2,        \r\n",
        "    horizontal_flip=True,\r\n",
        "    validation_split=0.3)  \r\n",
        "\r\n",
        "train_gen = generator.flow_from_directory(\r\n",
        "    train_dir,\r\n",
        "    target_size = (150,150),\r\n",
        "    batch_size=8,\r\n",
        "    class_mode = 'categorical'\r\n",
        ")\r\n",
        "\r\n",
        "test_gen = generator.flow_from_directory(\r\n",
        "    test_dir,\r\n",
        "    target_size=(150,150),\r\n",
        "    batch_size=8,\r\n",
        "    class_mode='categorical'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a3LE0GhixUV"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\r\n",
        "from keras.models import Model\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Flatten\r\n",
        "base_model = VGG19(include_top = False, weights = 'imagenet', input_shape = (150,150,3), classes = 6)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6TC1bFme3VE"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "model= Sequential()\r\n",
        "model.add(base_model)\r\n",
        "\r\n",
        "input_shape = (150,150,3)\r\n",
        "\r\n",
        "from keras.layers import Dense, Conv2D\r\n",
        "\r\n",
        "from keras import layers\r\n",
        "model.add(keras.Input(shape=input_shape))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Conv2D(256, (3, 3), activation='relu'))\r\n",
        "model.add(BatchNormalization())\r\n",
        "model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "model.add(layers.Dense(1024, activation='relu'))\r\n",
        "\r\n",
        "model.add(layers.Dense(6, activation='softmax'))\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsfvqKxPffSI"
      },
      "source": [
        "opt = Adam(lr=2e-4)\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    loss='binary_crossentropy',\r\n",
        "    optimizer=opt,\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "    \r\n",
        "history = model.fit_generator(\r\n",
        "    train_gen, \r\n",
        "    steps_per_epoch  = 500, \r\n",
        "    validation_data  = test_gen,\r\n",
        "    validation_steps = 500,\r\n",
        "    epochs = 20, \r\n",
        "    verbose = 1,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPH-7_-dfjBV"
      },
      "source": [
        "model_json = model.to_json()\r\n",
        "with open(\"model.json\",\"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "    \r\n",
        "model.save(\"model.h5\")\r\n",
        "print(\"Weights Saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCoB8u_HfwZB"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "N = np.arange(0, 20)\r\n",
        "plt.style.use('ggplot')\r\n",
        "plt.figure()\r\n",
        "plt.plot(N, history.history['loss'], label='train_loss')\r\n",
        "plt.plot(N, history.history['val_loss'], label='val_loss')\r\n",
        "plt.plot(N, history.history['accuracy'], label='train_accuracy')\r\n",
        "plt.plot(N, history.history['val_accuracy'], label='val_accuracy')\r\n",
        "plt.title('Training loss and accuracy')\r\n",
        "plt.xlabel('Epoch #')\r\n",
        "plt.ylabel('Loss/Accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix_A5HPNf1pT"
      },
      "source": [
        "Y_pred = model.predict_generator(test_gen, 500)\r\n",
        "y_pred = np.argmax(Y_pred, axis=1)\r\n",
        "print('Confusion Matrix')\r\n",
        "print(confusion_matrix(test_gen.classes, y_pred))\r\n",
        "print('Classification Report')\r\n",
        "target_names = ['Buildings', 'Forest', 'Glacier', 'Mountain', 'Sea', 'Street']\r\n",
        "print(classification_report(test_gen.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}